{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alphabet Inc. (NASDAQ:GOOG) Q3 2023 Earnings Call Transcript October 24, 2023 4:30 PM ET\n",
      "\n",
      "Company Participants\n",
      "\n",
      "Jim Friedland - Director of Investor Relations\n",
      "\n",
      "Sundar Pichai - Chief Executive Officer\n",
      "\n",
      "Philipp Schindler - Chief Business Officer\n",
      "\n",
      "Ruth Porat - Chief Financial Officer\n",
      "\n",
      "Conference Call Participants\n",
      "\n",
      "Brian Nowak - Morgan Stanley\n",
      "\n",
      "Doug Anmuth - JPMorgan\n",
      "\n",
      "Eric Sheridan - Goldman Sachs\n",
      "\n",
      "Lloyd Walmsley - UBS\n",
      "\n",
      "Michael Nathanson - MoffettNathanson\n",
      "\n",
      "Justin Post - Bank of America\n",
      "\n",
      "Ken Gawrelski - Wells Fargo\n",
      "\n",
      "Mark Mahaney - Evercore\n",
      "\n",
      "Operator\n",
      "\n",
      "Welcome, everyone. Thank you for standing by for the Alphabet Third Quarter 2023 Earnings Conference Call. At this time, all participants are in listen-only mode. After the speaker presentation, there will be a question-and-answer session. [Operator Instructions] I would now like to hand the conference over to your speaker today, Jim Friedland, Director of Investor Relations. Please go ahead.\n",
      "\n",
      "Jim Friedland\n",
      "\n",
      "Thank you. Good afternoon, everyone, and welcome to Alphabet's third quarter 2023 earnings conference call. With us today are Sundar Pichai, Philipp Schindler and Ruth Porat.\n",
      "\n",
      "Now, I'll quickly cover the safe harbor. Some of the statements that we make today regarding our business operations and financial performance may be considered forward-looking. Such statements are based on current expectations and assumptions that are subject to a number of risks and uncertainties. Actual results could differ materially. Please refer to our Form 10-K, including our Risk Factor section and our Form 10-Qs. We undertake no obligation to update any forward-looking statement.\n",
      "\n",
      "During this call, we will present both GAAP and non-GAAP financial measures. A reconciliation of non-GAAP to GAAP measures is included in today's earnings press release, which is distributed and available to the public through our investor relations website located at abc.xyz/investor. Our comments will be on year-over-year comparisons unless we state otherwise.\n",
      "\n",
      "And now, I'll turn the call over to Sundar.\n",
      "\n",
      "Sundar Pichai\n",
      "\n",
      "Thank you, Jim, and hello, everyone. I'm pleased with our business results this quarter, which demonstrates strong growth in Search and YouTube and momentum in Cloud. Google turned 25 in September, which offered an opportunity to reflect on our progress over the last quarter century and to look ahead to the opportunities enabled by AI we are so excited and confident about.\n",
      "\n",
      "Our product momentum continued this quarter, as you saw with Cloud Next, Made on YouTube and Made by Google. It's all part of our focus on making AI more helpful for everyone, and we are making good progress across the four areas that we shared last quarter. First, improving knowledge and learning. This includes our work with the Search Generative Experience, which is our experiment to bring Generative AI capabilities into Search. We have learned a lot from people trying it, and we have added new capabilities, like incorporating videos and images into responses and generating imagery. We've also made it easier to understand and debug generated code.\n",
      "\n",
      "Direct user feedback has been positive with strong growth and adoption. In August, we opened up availability to India and Japan with more countries and languages to come. As we add features and expand into new markets, we are engaging with the broader ecosystem and will continue to prioritize approaches that add value for our users, send valuable traffic to publishers, and support a healthy open Internet. With Generative AI applied to Search, we can serve a wider range of information needs and answer new types of questions, including those that benefit from multiple perspectives. We are surfacing more links with SGE and linking to a wider range of sources on the results page, creating new opportunities for content to be discovered.\n",
      "\n",
      "Of course, ads will continue to play an important role in this new Search experience. People are finding ads helpful here as they provide useful options to take action and connect with businesses. We'll experiment with new formats native to SGE that use Generative AI to create relevant high-quality ads customized to every step of the Search journey.\n",
      "\n",
      "The second area we are focused on is boosting creativity and productivity. Bard is particularly helpful here. It's a direct interface to a conversational LLM, and we think of it as an early experiment and complementary experience to Google Search. Bard can now integrate with Google apps and services, showing relevant information from Workspace, Maps, YouTube, and Google Flights and Hotels. We've also improved the Google it feature. It provides other sources to help people evaluate Bard's responses and explore information across the web.\n",
      "\n",
      "Earlier this month, we announced Assistant with Bard, a personal assistant powered by Generative AI. It combines Bard's generative and reasoning capabilities with Assistant's personalized help. You can interact with it through text, voice, or images, and in the coming months, you'll be able to opt in on Android and iOS mobile devices. Our collaborative tools in Workspace and YouTube are also part of how we boost creativity and productivity, and they are seeing great initial traction.\n",
      "\n",
      "Third, we are enabling developers, businesses, and other organizations to build their own transformative products and services. For example, thousands of customers and partners are already using Google Cloud to capture the potential of AI and we'll share more there in a minute.\n",
      "\n",
      "And fourth, we are building and deploying AI responsibly, so that everyone can benefit. One area we are focused on is making sure people can more easily identify when they are encountering AI-generated content online. Using new technology powered by Google DeepMind SynthID, images generated by Vertex AI can be watermarked in a way that is invisible to the human eye without reducing the image quality. Underlying all this work is the foundational research done by our teams at Google DeepMind and Google Research. We are excited to roll out more of what they've been working on soon.\n",
      "\n",
      "As we expand access to our new AI services, we continue to make meaningful investments in support of our AI efforts. We remain committed to durably re-engineering our cost base in order to help create capacity for these investments in support of long-term sustainable financial value. Across Alphabet, teams are looking at ways to operate as effectively as possible focused on their biggest priorities.\n",
      "\n",
      "Turning next to YouTube, which saw solid momentum in both its ads and subscription businesses in Q3. NFL Sunday Ticket is now live and receiving excellent reviews. Fans love our multi-view feature, which can live stream up to four games on a single screen. Weâ€™ve heard positive feedback from our partners at the NFL about the new features and live stream reliability. This is a clear example of our ability to execute big partnerships with excellence and at scale.\n",
      "\n",
      "I'm really pleased with the growth and engagement on YouTube Shorts. We continue to work on closing the monetization gap here. Shorts now average over 70 billion daily views and are watched by over 2 billion signed-in users every month. At Made on YouTube in September, we announced new tools that make it easier to create engaging content. Dreamscreen is an experimental feature that allows creators to add AI-generated video or image backgrounds to shorts. And YouTube Create is a new mobile app with a suite of production tools for editing shorts, longer videos, or both.\n",
      "\n",
      "Next, Google Cloud. We see continued growth with Q3 revenue of $8.4 billion, up 22%. Today, more than 60% of the world's 1,000 largest companies are Google Cloud customers. At Cloud Next, we showcased amazing innovations across our entire portfolio of infrastructure, data and AI, workspace collaboration, and cybersecurity solutions. We offer advanced AI-optimized infrastructure to train and serve models at scale. And today, more than half of all funded Generative AI startups are Google Cloud customers. This includes AI21 Labs, Contextual, Elemental Cognition, Rytr, and more.\n",
      "\n",
      "We continue to provide the widest choice of accelerator options. Our A3 VMs powered by NVIDIA's H100 GPU are generally available, and we are winning customers with Cloud TPU v5e, our most cost efficient and versatile accelerator to date. On top of our infrastructure, our Vertex AI platform helps customers build, deploy, and scale AI-powered applications. We offer more than 100 models, including popular third-party and open source models, as well as tools to quickly build, search, and conversation use cases. From Q2 to Q3, the number of active Generative AI projects on Vertex AI grew by 7x, including Highmark Health, which is creating more personalized member materials.\n",
      "\n",
      "Duet AI was created using Google's leading large foundation models and especially trained to help users to be more productive on Google Cloud. We continue expanding its capabilities and integrating it across a wide range of cloud products and services. With Duet AI, we are helping leading brands like PayPal and Deutsche Bank boost developer productivity. And we are enabling retailers like Aritzia and Gymshark to gain new insights for better and faster business results. In fact, companies are increasingly using AI for the purpose of analyzing data. And customers are choosing Google Cloud because we are the only large cloud provider with a unified platform to analyze structured and unstructured data. In Workspace, thousands of companies and more than a million trusted testers have used Duet AI. They are writing and refining content in Gmail and Docs, creating original images from text within slides, organizing data in Sheets and more. These innovations enable us to provide new services and grow our base of 10 million paying customers, including enterprises like Grupo Boticario, Unilever and Warner Music.\n",
      "\n",
      "We also integrated Duvet AI across our cybersecurity portfolio to differentiate in the marketplace, providing Generative AI-powered assistance in Mandiant Threat Intelligence, Chronicle Security Operations, and Security Command Center. This reduces the time security teams spend writing, running, and refining searches by seven times. We are the only leading security provider that combines frontline intelligence and expertise, a modern security operations platform, and a trusted cloud foundation, all infused with Generative AI, helping protect customers and partners like BT, Jack Henry & Associates, and CoverMyMeds.\n",
      "\n",
      "Turning to hardware. We unveiled our new products this month. We introduced our new Pixel 8, Pixel 8 Pro, and Pixel Watch 2 to very positive consumer feedback and reviews. Pixel is the fastest growing smartphone brand in our top markets and the only one that grew in units sold year-over-year. Our portfolio of Pixel products are brought to life, thanks to our combination of foundational technologies, AI, Android, and Google Tensor. Google Tensor G3 is the third generation of our tailor-built chip. It's designed to power transformative experiences by bringing the latest in Google AI research directly to our newest phones. A new AI-powered editing features in Google Photos on Pixel 8 and Pixel 8 Pro remove distractions, generate the best shot from multiple images and reduce distracting sounds in videos.\n",
      "\n",
      "Pixel and our third-party ecosystem are powered by Android. We just released Android 14 with more accessibility features. I also want to mention Chromebook Plus, a new category which provides the best of Chrome on great hardware with built-in Google Apps and powerful AI capabilities. We also shared that Chromebooks will now get regular automatic updates for 10 years, more than any other operating system.\n",
      "\n",
      "In Other Bets, Waymo is onboarding more riders to its commercial ride hailing service as it gradually adds over 100,000 people from its San Francisco waitlist. Austin will follow as its next ride hail city. Wing and Walmart announced a new partnership to provide drone delivery service in the Dallas-Fort Worth area.\n",
      "\n",
      "Before handing over to Philipp, I want to thank our employees around the world who are working to create innovative products and provide great services to people and businesses who use our products. Philipp?\n",
      "\n",
      "Philipp Schindler\n",
      "\n",
      "Thanks, Sundar, and hi, everyone. I'll start with our performance for the quarter and then give color into the three key priority areas for ads. Google AI, Retail and YouTube that we've identified on past calls as opportunities for long-term growth in advertising. Google Services revenues of $68 billion were up 11% year-on-year.\n",
      "\n",
      "In Google Advertising, Search and Other, revenues grew 11% year-on-year, led by solid growth in the Retail vertical. In YouTube Ads, revenues were up 12% year-on-year, driven by growth in both brand and direct response. In Network, revenues declined 3% year-on-year. Google Other revenues were up 21% year-on-year, led by strong growth in YouTube subscription revenues.\n",
      "\n",
      "Let's start with Google AI. Recent dramatic advances in everything from foundational research models to LLM to Generative AI are improving our ability to deliver better performance and profitability for advertisers and more helpful, delightful experiences for users. We covered many innovations last quarter after GML, like our conversational experience in Google Ads, significant updates to Performance Max and new campaign types like Demand Gen. And as Sundar said, we're continuing to experiment with new ad formats on SGE. It's extremely important to us that in this new experience, advertisers still have the opportunity to reach potential customers along their Search journeys. I'll highlight more ways we're innovating with the best of Google AI as we double-click into our core business.\n",
      "\n",
      "In Retail, we had a great quarter. In a market where every dollar counts, our proven AI-powered solutions like Search and PMax are helping retailers drive reliable, strong ROI and meet customers wherever they are across the funnel. In Q3, we also started prepping retailers for what will be a long holiday season.\n",
      "\n",
      "Let me share some things. Number one, with a maximum number of days between Thanksgiving and Christmas and expectations for many micro peaks beyond Cyber-Five, we're arming businesses with insights and planning tools, including OptiScore and Performance Planner to uncover new opportunities, plan budgets and targets to stay competitive and be smarter with their inventory and pricing strategy.\n",
      "\n",
      "Number two. Consumer expectations are shifting, especially around price and convenience. We've seen 4x deals queries during the holidays versus other periods. 75% of users say they'll shop with those offering free shipping. Retailers are capitalizing on these trends with our differentiated merchant offerings like merchant promotions and fulfillment options. And we're making improvements to significantly boost the number of deals shown to shoppers in Search this holiday season. Look out for more in the coming days about new ways we'll help shoppers browse deals across the web this year.\n",
      "\n",
      "Number three. No surprise, omni-channel is the way to succeed. With our suite of omni product solutions, including local inventory ads, omnibidding, and PMax for store goals, retailers big and small, are capturing demand and incremental store budgets while engaging with high value customers. Innovation continues across our shopping and merchant experiences powered by Google AI. Our virtual try-on tool for apparel launched in June and has been a hit with consumers and brands. Users engage with virtual try-on images at a higher rate versus regular brand provided images.\n",
      "\n",
      "Product Studio is another launch from GML getting positive feedback in pilot mode. It uses the best of Gen.AI to help businesses create unique and tailored imagery for free that they can then scale across their channels. We're seeing early merchant testers using it to seasonalize their content for the holidays.\n",
      "\n",
      "Let's shift to YouTube. It's worth repeating, our intense focus on creator success coupled with our multi-format strategy are at the center of how we think about YouTube's long-term growth. Shorts, connected TV and our subscription offerings are key drivers here and we're investing across each to solidify YouTube's position as the best place to create, the best place to watch and the best place to deliver results.\n",
      "\n",
      "Sundar mentioned watch time and engagement momentum on shorts as well as our monetization progress. He also covered subscription growth and NFL Sunday Ticket. As for connected TV, we continue to be the number one overall streaming destination according to Nielsen. 150 million plus people are watching YouTube on CTV screens every month in the US. Whether it's music videos, NFL Sunday Ticket, free movies, shorts, a continuous stream of MrBeast or some other creator-led content, viewers want choice and variety, and we're giving it to them all in one place. And to help creators and advertisers connect with these billions of viewers across moments, screens, and formats, we're bringing Google AI to awesome new creation tools and ad solutions.\n",
      "\n",
      "AI will do wonders for creation and storytelling. From Dreamscreen and YouTube Create, which Sundar talked about, to features that audit up content in multiple languages, flip and trim existing assets, remix and clip videos, and more, we're just getting started. We're also helping brands break through at speed and scale across the funnel to drive results. Spotlight Moments launched last week. It uses AI to identify trending content around major cultural moments for brand sponsorship opportunities. There's video reach campaigns, which are expanding to in-feed and shorts and will be generally available in November. AI is helping advertisers find as many people as possible in their ideal audience for the lowest possible price. Early tests are delivering 54% more reach at 42% lower cost.\n",
      "\n",
      "And then with video view campaigns, AI is serving skippable ads across in-stream, in-feed, and shorts and helping advertisers earn the maximum number of views at the lowest possible cost. So far, they're driving 40% more views on average versus in-stream alone. Then for YouTube and other feed-based services, there's our new Demand Gen campaign, which launched in April, rolled out worldwide last week, and was designed for the needs of today's social marketers to engage people as they stream, scroll and connect. It combines video and image ads in one campaign with access to 3 billion users across YouTube and Google, and the ability to optimize and measure across the funnel using Google AI. Demand Gen is already driving success for brands like Samsung and Toyota.\n",
      "\n",
      "Before I wrap, one quick highlight on our close collaboration and commitment to our most important ecosystems and partners. In July, we launched Google News Showcase in the US, our curated online news experience and licensing program with more than 150 news publications, 90% of which are local or regional. Globally, over 2,500 news publications have signed onto News Showcase, and the product is live in 23 countries today. Our commitment to open access to news and information remains strong.\n",
      "\n",
      "With that, I'll end with a thank you to our customers and partners around the world for their continued trust and collaboration, and our Googlers everywhere for their incredible hard work and dedication. Ruth, over to you.\n",
      "\n",
      "Ruth Porat\n",
      "\n",
      "Thank you, Philipp. We are very pleased with our financial results for the third quarter, driven by meaningful growth in Search and YouTube and momentum in Cloud. My comments will be on year-over-year comparisons for the third quarter, unless I state otherwise.\n",
      "\n",
      "I will start with results at the Alphabet level followed by segment results and conclude with our outlook. For the third quarter, our consolidated revenues were $76.7 billion, up 11% in both reported and constant currency. Search remained the largest contributor to revenue growth. In terms of expenses, total cost of revenues was $33.2 billion, up 7%, primarily reflecting other cost of revenues of $20.6 billion, which was up 6%. Growth here was primarily driven by content acquisition costs mainly for YouTube subscription offerings. As noted in our earnings release, the overall increase in data center and other operations costs was partially offset by a reduction in depreciation expense due to the change in estimated useful lives we made starting in the first quarter of the year.\n",
      "\n",
      "Operating expenses were $22.1 billion, up 6% reflecting the following. First, an increase in R&D expenses, driven primarily by compensation. Second, an increase in G&A expenses, reflecting the impact of charges related to legal matters. And finally, sales and marketing expenses, which were relatively flat to last year.\n",
      "\n",
      "Operating income was $21.3 billion, up 25%, and our operating margin was 28%. Other income and expense was a loss of $146 million. Net income was $19.7 billion. This reflects an effective tax rate of 7% in the third quarter from an IRS change related to the use of foreign tax credits, which had an outsized impact on the third quarter rate because the change resulted in a catch-up for prior periods.\n",
      "\n",
      "We delivered free cash flow of $22.6 billion in the third quarter and $78 million for the trailing 12 months. We ended the quarter with $120 billion in cash and marketable securities. As a reminder, our cash balance and free cash flow in the second and third quarters benefited from the deferral of certain tax payments to the fourth quarter of 2023.\n",
      "\n",
      "As noted in our earnings release, on October 16, we made an estimated tax payment of $10.5 billion related to this deferral, which will be reflected in our cash balance and free cash flow in the fourth quarter.\n",
      "\n",
      "Turning to segment results. Within Google Services, revenues were $68 billion, up 11%. Google Search and other advertising revenues of $44 billion in the quarter were up 11%, led again by growth in retail. YouTube advertising revenues of $8 billion were up 12%, driven by both brand advertising and direct response. Network advertising revenues of $7.7 billion were down 3%. Other revenues were $8.3 billion, up 21%, primarily reflecting growth in YouTube non-advertising revenues driven by subscriber growth in YouTube TV followed by YouTube Music Premium. TAC was $12.6 billion, up 7%. Google Services operating income was $23.9 billion, up 27% and the operating margin was 35%.\n",
      "\n",
      "Turning to the Google Cloud segment. Revenues were $8.4 billion for the quarter, up 22%. GCP revenue growth remained strong across geographies, industries and products, although the Q3 year-on-year growth rate reflects the impact of customer optimization efforts. Google Workspace also delivered strong revenue growth, primarily driven by increases in average revenue per seat. Google Cloud had operating income of $266 million, and the operating margin was 3%. As to our Other Bets, for the third quarter, revenues were $297 million and the operating loss was $1.2 billion.\n",
      "\n",
      "Turning to our outlook for the business. With respect to Google Services. First, within advertising. After a period of historic volatility, we were pleased with the year-on-year revenue growth of Search and YouTube advertising in the third quarter. Second, within other revenues, in our YouTube subscription products the substantial growth in revenues primarily reflects subscriber growth. Looking ahead, a full quarter of NFL Sunday Ticket revenues as well as associated content acquisition costs will be reflected in Q4 results compared to only a few weeks in the third quarter.\n",
      "\n",
      "Play had growth in the third quarter, driven primarily by an increase in the number of buyers. With respect to hardware, there is a headwind to revenues in the fourth quarter, reflecting efforts to optimize the portfolio with tighter targeting of our go-to-market investments as well as the ongoing impact from the difference in launch timing for the Pixel 6a and 7a that we mentioned last quarter.\n",
      "\n",
      "Turning to Google Cloud. We are pleased with the ongoing customer engagement with GCP and Workspace and the potential benefit of our AI solutions including infrastructure and services such as Vertex AI and Duet. We continue to invest aggressively given the significant potential we see while remaining focused on profitable growth. In terms of expenses and profitability, we're pleased with our operating performance. As we have repeatedly stressed, we remain focused on durably reengineering our cost base to create investment capacity to support our growth priorities, most important of which is with AI.\n",
      "\n",
      "We have a number of workstreams in place. First, we are maintaining a slower pace of headcount growth, reflecting product prioritization and reallocation of talent to support our most important growth opportunities. Second, we remain focused on optimizing our real estate footprint, including how and where we work to reduce our expense growth. As you can see from our earnings release, we incurred $207 million in accelerated rent and depreciation in the third quarter related to these actions. Third, we have engineering work streams underway to improve productivity across Alphabet. Given the magnitude of investment in our technical infrastructure, we have a superb team focused on efficiency of our operations there. We are also making progress in streamlining operations across Alphabet through the use of AI. Finally, there are ongoing workstreams that are improving the efficiency of our spend with suppliers and vendors through our central procurement organization. And to be clear, across the portfolio of other bet companies, we have also been working to identify opportunities to create sharper focus and to operate more efficiently and effectively.\n",
      "\n",
      "With respect to sequential quarter-on-quarter trends, two further points. First, cost of sales in the fourth quarter will reflect both higher hardware costs given Pixel family launches as well as increased CAC for YouTube as previously noted. Second, as usual, we expect sales and marketing expenses to be more heavily weighted to the end of the year, in part to support product launches in the holiday season. Finally, our reported CapEx in Q3 was $8 billion, driven overwhelmingly by investment in our technical infrastructure with the largest component for servers, followed by data centers, reflecting a meaningful increase in our investments in AI compute.\n",
      "\n",
      "The growth in reported cash CapEx in Q3 is somewhat muted due to the timing of supplier payments, which can cause variability from quarter-to-quarter. We continue to invest meaningfully in the technical infrastructure needed to support the opportunities we see in AI across Alphabet and expect elevated levels of investment, increasing in the fourth quarter of 2023 and continuing to grow in 2024.\n",
      "\n",
      "In closing, we remain very excited about the opportunities ahead and committed to deliver sustainable financial value. Thank you. Sundar, Philipp and I will now take your questions.\n",
      "\n",
      "Question-and-Answer Session\n",
      "\n",
      "Operator\n",
      "\n",
      "[Operator Instructions] And our first question comes from Brian Nowak with Morgan Stanley. Your line is open.\n",
      "\n",
      "Brian Nowak\n",
      "\n",
      "Great. Thanks for taking my question. I have two. The first one, maybe a sort of a jump ball. There's somewhat of an investor debate about sort of the incremental return on capital to Search when it comes to AI. I know it's early, but are there any examples that you're seeing with SGE or Bard on higher utility, higher conversion rates, more engagement, just something to sort of show signal around the return that could come from these investments? And the second one, Ruth, I know you've spoken a lot about durably reengineering the cost base. I think in the past, you've talked about how expenses could grow slower than revenue in 2024. Is that sort of still the high-level way to think about it or is that potentially changing a bit as investments are continuing? Thanks.\n",
      "\n",
      "Sundar Pichai\n",
      "\n",
      "Ruth, do you want to take the second part?\n",
      "\n",
      "Ruth Porat\n",
      "\n",
      "Sure. Thanks for that, Brian. So overall, that's sort of a truism as you know well, that looking to grow revenues at a faster rate than expenses as we're focused on delivering sustainable financial value. And so that really takes us to the work streams, which I tried to tick through, again, those remain the driver. They're the real priority there -- those are the efforts that are going to enable us to expense growth as moderated as possible while supporting the investment growth that is so exciting in front of us, in particular, around AI.\n",
      "\n",
      "Sundar Pichai\n",
      "\n",
      "And to your first part, obviously, we see AI as a foundational platform shift and are excited about the opportunities across our business. It starts with Search. And I've been pretty pleased with how the user feedback has been on SGE. We are rolling it out to more users. Through it all, we are making sure the product works well, and we are generating value for our ecosystem, and that adds transition as well. And I think I view this is, with AI, the opportunity to evolve Search and Assistant over the next decade ahead. And I think as we've always seen, when you continue to invest and build great experiences, you can get value on the other side. And I do think over time, there will be newer pads, just like we have done on YouTube, I think with the AI work that are subscription models is a possible path as well. And obviously, all of the AI investments we are doing applies across Cloud, too, and I'm pretty optimistic about what's ahead there as well.\n",
      "\n",
      "Brian Nowak\n",
      "\n",
      "Great. Thank you, both.\n",
      "\n",
      "Operator\n",
      "\n",
      "Your next question comes from Doug Anmuth with JPMorgan. Your line is open.\n",
      "\n",
      "Doug Anmuth\n",
      "\n",
      "Thanks for taking the questions. One for Sundar and one for Ruth. Just, Sundar, you talked a lot about AI. I was hoping you could talk more about Gemini and how we'll differentiate from other models, some of the multimodal capabilities and what new experiences or agents do you think it could unlock and how we should think about timing? And then also just on Cloud, I hope you can talk about some of the factors there on the decel in Cloud and just what you're seeing in terms of optimizations? And is there any sign of new workload deployments taking place? Thanks.\n",
      "\n",
      "Sundar Pichai\n",
      "\n",
      "Thanks. Good questions. On Gemini, obviously, it's effort from our combined Google DeepMind team. I'm very excited at the progress there and as we're working through getting the model ready. To me, more importantly, we are just really laying the foundation of what I think of as the next generation series of models we'll be launching throughout 2024. The pace of innovation is extraordinarily impressive to see. We are creating it from the ground-up to be multimodal, highly efficient tool and API integrations and more importantly, laying the platform to enable future innovations as well. And we are developing Gemini in a way that it is going to be available at various sizes and capabilities, and we'll be using it immediately across all our products internally as well as bringing it out to both developers and cloud customers through Vertex. So I view it as a journey and each generation is going to be better than the other, and we are definitely investing and the early results are very promising. On Cloud, maybe what I would say is, overall, we had definitely started seeing customers looking to optimize spend. We leaned into it to help customers given some of the challenges they were facing. And so that was a factor. But we are definitely seeing a lot of interest in AI. There are many, many projects underway now, just on Vertex alone, the number of projects grew over 7x. And so we see signs of stabilization, and I'm optimistic about what's ahead.\n",
      "\n",
      "Doug Anmuth\n",
      "\n",
      "Thank you, Sundar.\n",
      "\n",
      "Operator\n",
      "\n",
      "Your next question comes from Eric Sheridan with Goldman Sachs. Your line is now open.\n",
      "\n",
      "Eric Sheridan\n",
      "\n",
      "Thank you, sir, very much for taking the questions. Two, if I could. Sundar, you guys led over a year ago, starting with Performance Max. And I wanted to know if we could get your updated thoughts on how AI might impact the broader advertising industry and how you're aligning Alphabet in Google's goals with AI and where it might take the advertising industry in the years ahead? That would be the first question. And then about a year ago, Philipp and Ruth started talking about some of the brand advertising headwinds that YouTube was facing. As we start to lap those headwinds, how should we be thinking about a broad recovery in brand advertising versus elements of still headwinds that are being faced in the broader ad space, specifically with YouTube? Thank you.\n",
      "\n",
      "Philipp Schindler\n",
      "\n",
      "So maybe I take the first one. We're very pleased with how Performance Max is performing. It gives advertisers really maximum performance across all inventory from, one, really AI-powered campaign, and it's probably the ultimate example of AI in action across our ads product. It's delivering excellent ROI. Those using it achieve like on average, over 18% more conversions at a similar cost per action. So since rolling it out about two years ago, we've continued to expand the features, give advertisers additional ways to steer how it works. There are a lot of things like account level, negative keywords, other details here. We launched new life cycle goals, customer life cycle goals, we call them revamped asset creation flow. That really helps business adapt and scale the most successful creatives. I think that's one to watch.\n",
      "\n",
      "We will also continue to build other new PMax features based on all the advertiser feedback we're seeing. So we're very, very encouraged by the progress here. Overall, maybe there was a second part to your question a bit on what we're hearing from the customers out there, look, driving ROI and efficiency is still top of mind for many, right? It's a rapidly shifting and still quite unpredictable consumer landscape out there. Our AI tools are very well received. AI, Gen AI are top of mind for everybody, really. There's a ton of excitement, lots of questions about it. Many understand the value. Nearly 80% of our advertisers already use at least one AI-powered search ads product. And yeah, we're hearing a lot of good feedback on, number one, our ads AI essentials, which are really helping to unlock the power of AI and set up for durable ROI growth on the advertiser side. This is -- those are products like the foundation for data and measurement, things like Google Tag, Consent Mode and so on. And obviously, Search and PMax we talked about it and then all the Gen AI products, all those different ones. So there's a whole lot of interest in those products, yeah.\n",
      "\n",
      "Ruth Porat\n",
      "\n",
      "And then on to your second question regarding YouTube, as we said, overall year-on-year growth in revenues was driven by both brand advertising and direct response. But very much to your question, yes, there was a stabilization in spending by advertisers. We're really pleased about that. We're particularly pleased about the ongoing performance in the Living Room and on Shorts. And as I said, that's both watch time growth and monetization I'd say the other thing benefiting YouTube is the retail strength we talked about with Search, retail strength in APAC in both Search and YouTube, and that really began in the second quarter, continued in the third quarter, but that was another contributor. So quite a number of things going on. I feel good about the results the team was able to deliver here.\n",
      "\n",
      "Eric Sheridan\n",
      "\n",
      "Thank you so much.\n",
      "\n",
      "Operator\n",
      "\n",
      "Your next question comes from Lloyd Walmsley with UBS. Your line is open.\n",
      "\n",
      "Lloyd Walmsley\n",
      "\n",
      "Great. Thanks for taking the question. Two, if I can, First, as we just think about the rollout of SGE across the user base, like how far along is that? And how do you balance the product rollout and consumer uptake versus monetization in that transition? And then the second one, also sort of Generative AI related. How quickly are you guys finding new ways of optimizing whether that's shrinking model sizes, chip efficiencies or anything else? And do you think overall capital intensity of the business scales up or do you just find ways to do this more efficiently as usage scales? Anything you could share there would be great. Thanks.\n",
      "\n",
      "Sundar Pichai\n",
      "\n",
      "On the first part about SGE, we are still in a very -- very early days in terms of how much we have rolled it out, but we have definitely gotten it out to enough people in both geographically across user segments and enough to know that the product is working well. It improves the experience and -- but there are areas to improve, which we are fine tuning. Our true north here is getting at the right user experience we want to and pretty comfortable seeing the trajectory. And we've always worked through these transitions, be it from desktop to mobile, or from now mobile to an AI-enhanced experience. And so it's nothing new, and I feel very comfortable that as we go through it, the strength of our teams, both on the organic side as well as ad side to drive the right experience for users, including ads will pay dividends.\n",
      "\n",
      "So -- and I think we'll continue to make improvements and make progress there. On your second question, at a high level, I would say, all through the -- we just celebrated 25 years and of all the things I was proud about when I looked at the strength of the work we have done across our infrastructure as a company, our technical infrastructure as a company and various given stages at a given moment in time, when we adopted new generations of technology, we have looked at the cost of it. But then the curves, the efficiency curves we have driven on top of it has always been phenomenal to see. And I see the current moment is no different. Already through this year, we are driving significant efficiencies, both in our models, in training costs and serving costs and our ability to adapt what's needed to the right use case. And so I think we'll do everything that is needed to make sure we have the leading AI models and infrastructure in the world, bar none, and will continue driving efficiencies from there.\n",
      "\n",
      "Lloyd Walmsley\n",
      "\n",
      "Okay. Thank you.\n",
      "\n",
      "Operator\n",
      "\n",
      "Your next question comes from Michael Nathanson with MoffettNathanson. Your line is now open.\n",
      "\n",
      "Michael Nathanson\n",
      "\n",
      "Thank you. I'm going to ask you guys a multipart question on YouTube TV. So firstly, what were the broader objectives for getting Sunday Ticket? How does it perform versus those objectives? What lessons have you learned from having the NFL Sunday Ticket and how does that affect your appetite for more sports going forward? Thanks.\n",
      "\n",
      "Philipp Schindler\n",
      "\n",
      "So, as Sundar said earlier, we're several weeks into our first season, and we're very pleased with how it's going, I think, in the broader context, you have to look at it as overall a YouTube subscription strategy. The great feedback we've gotten so far on the YouTube experience is very, very significant. People love the navigation. They love multi-view, they love the chats and the poles and frankly, people are very happy with the lack of latency here. The number one piece of concrete feedback the team has gotten is actually that people want the ability to pick their own games from multi-view which is -- multi-view is the awesome feature, we started rolling out on YouTube TV that gives fans the ability to basically watch multiple streams here at once. And yeah, overall, the teams are working hard to build a fantastic experience, and we are really trying to stay focused on getting our first season right and providing the best possible experience really for fans here.\n",
      "\n",
      "Michael Nathanson\n",
      "\n",
      "Thank you.\n",
      "\n",
      "Operator\n",
      "\n",
      "Your next question comes from Justin Post with Bank of America. Your line is now open.\n",
      "\n",
      "Justin Post\n",
      "\n",
      "Great. Thanks. A couple of questions on Q4. Can you provide any color on if there's been any pause in advertising around the Middle East conflict in October, anything we should be aware of for Q4? And then second, when we do think about the Sunday Ticket impact, I know you can't give us revenues or expenses, but overall, would that be a headwind to margins in Q4 or something we should be thinking about? Thank you.\n",
      "\n",
      "Ruth Porat\n",
      "\n",
      "So, look, on your -- on the first question, obviously, this is a tragic, tragic -- there are no words to talk about what's going on. And all of our focus has been on supporting our people there and how our products can be as helpful as possible in this very painful time, broadly. And so nothing really to add.\n",
      "\n",
      "And then in terms of the second question, Sunday Ticket, the only thing I tried to call out there is that clearly, this is the first full quarter of Sunday Ticket that is contributing overall to the subscription revenues that we see. That's in part of other revenues also, obviously, is contributing to higher CAC in the fourth quarter. So try to make that really clear. And as we look longer term, we expect to generate an attractive return over the life of the deal. We're continuing to invest in support of this and excited about the additional opportunities that come out of it, working with partners to deliver clips and other opportunities.\n",
      "\n",
      "As we've said, we've heard positive feedback from our partners at the NFL about the new features and live stream reliability. And this is really a clear example of our ability to execute big partnerships with excellence at scale and really leverage a lot of the extraordinary magic at YouTube and across Google, and that's what we're excited about.\n",
      "\n",
      "Justin Post\n",
      "\n",
      "Great. Thank you.\n",
      "\n",
      "Operator\n",
      "\n",
      "Your next question comes from Ken Gawrelski with Wells Fargo. Your line is now open.\n",
      "\n",
      "Ken Gawrelski\n",
      "\n",
      "Thank you so much. Two questions, if I may. First, how do you think about the future -- the future structure of AI-driven search capabilities? Will activity remain centralized in a Search bar or will it be decentralized and present in many different applications, including on third-party applications? You alluded to Bard being integrated into multiple Google experiences early in the call. And then the second question is, any update on the Chrome cookie deprecation plan to begin in 1Q '24. What have you seen so far based on your early testing of privacy sandbox and what advertiser feedback have you received?\n",
      "\n",
      "Sundar Pichai\n",
      "\n",
      "On your first question, look, I broadly think of it as people are looking for information. They always look for it in many, many different ways. We've given the product search example. People can directly go to Amazon as an example or come to Google. So if you zoom back and take an information view of the world, there's always been many different ways to get it. And part of our work we do in making Search be world-class and give users what they're looking for so that we can get it as much of that intent as possible. So I don't see that changing. With mobile, there were more ways people could get information, but we worked out to make Search work better in the mobile world. And similarly, a view with AI, there'll be many ways people get information, but it also offers us an opportunity in Search and in Assistant to take it to the next level and answer use cases, which we couldn't have done before and expand the diverse set of needs where we are sourced. So that's how I see the opportunity ahead.\n",
      "\n",
      "Philipp Schindler\n",
      "\n",
      "And to the second part of your question, yes, Chrome still plans to begin phasing out third-party cookies in the second half of '24. In the last several months, Chrome has really made significant progress on the privacy sandbox with APIs for developer testing, and they're not generally available in Chrome. Our ads team is testing these APIs. And as we shared back in April, the preliminary results of our interspace ads testing showed that a combination of what we call privacy preserving signals and AI optimization actually provides positive results for businesses preparing for a cookie-less future. We also recently announced that in Q1 of '24, we plan to deprecate third-party cookies for 1% of Chrome users, and this will support developers, obviously, in conducting their real-world experiments to assess the readiness and effectiveness of their products in this -- without third-party cookies. And we're overall encouraged by the ecosystem engagement on privacy sandbox. We'll continue to work with the industry and regulators in how these technologies can support the transition to, frankly, a more private web.\n",
      "\n",
      "Ken Gawrelski\n",
      "\n",
      "Thank you.\n",
      "\n",
      "Operator\n",
      "\n",
      "And our last question comes from Mark Mahaney with Evercore. Your line is now open.\n",
      "\n",
      "Mark Mahaney\n",
      "\n",
      "Thank you. Two questions, please. Ruth, you talked about these elevated levels of investments in Q4 and in '24. I'm sorry, were you referring to just CapEx or CapEx and total expenses? And then on the comments around stabilization in Cloud, is this something that you just started to see in the September quarter? Or had you seen that starting earlier in the year? And if you just started seeing in the September quarter, would you have any thoughts on why you would have seen it like Google Cloud would have seen it maybe later than some of the other hyperscalers? Thank you.\n",
      "\n",
      "Ruth Porat\n",
      "\n",
      "So I think what you're referring to is my CapEx comment. I was trying to make the point that we are committed to meaningfully investing in CapEx, given all the opportunities we see. We do continue to expect elevated levels of investment in our technical infrastructure. It it will be increasing in the fourth quarter and talked about some of the difference in timing, muted timing in the third quarter due to the timing of supplier payments and then try to make it clear that we will continue to grow CapEx in 2024 or more specifically to your question, 2024 aggregate CapEx will be above the full year 2023. So that was the main one.\n",
      "\n",
      "And then as it relates to Cloud, as Sundar said, what we're really excited about is the revenue growth does reflect healthy customer adoption across the portfolio, and that's infrastructure, data analytics, security. And so weâ€™re -- I can't comment on others, but we feel good about where we're sitting here and looking forward, and we'll let you do the forecasting. DCP growth in the third quarter was above the growth rate for Cloud overall, and we feel really good about the work that they're doing there. And then, of course, in addition to that is all of the contribution from Google Workspace.\n",
      "\n",
      "Mark Mahaney\n",
      "\n",
      "Thank you.\n",
      "\n",
      "Operator\n",
      "\n",
      "Thank you. And that concludes our question-and-answer session for today. I'd like to turn the conference back over to Jim Friedland for any further remarks.\n",
      "\n",
      "Jim Friedland\n",
      "\n",
      "Thanks, everyone, for joining us today. We look forward to speaking with you again in our fourth quarter 2023 call. Thank you, and have a good evening.\n",
      "\n",
      "Operator\n",
      "\n",
      "Thank you, everyone. This concludes today's conference call. Thank you for participating. You may now disconnect.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('Google_cocall.txt', 'r', encoding = 'utf-8') as f:\n",
    "    input = f.read()\n",
    "\n",
    "print((input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Alphabet Inc. (NASDAQ:GOOG) Q3 2023 Earnings Call Transcript October 24, 2023 4:30 PM ET\\n\\nCompany Participants\\n\\nJim Friedland - Director of Investor Relations\\n\\nSundar Pichai - Chief Executive Officer\\n\\nPhilipp Schindler - Chief Business Officer\\n\\nRuth Porat - Chief Financial Officer\\n\\nConference Call Participants\\n\\nBrian Nowak - Morgan Stanley\\n\\nDoug Anmuth - JPMorgan\\n\\nEric Sheridan - Goldman Sachs\\n\\nLloyd Walmsley - UBS\\n\\nMichael Nathanson - MoffettNathanson\\n\\nJustin Post - Bank of America\\n\\nKen Gawrelski - Wells Fargo\\n\\nMark Mahaney - Evercore\\n\\nOperator\\n\\nWelcome, everyone. Thank you for standing by for the Alphabet Third Quarter 2023 Earnings Conference Call. At this time, all participants are in listen-only mode. After the speaker presentation, there will be a question-and-answer session. [Operator Instructions] I would now like to hand the conference over to your speaker today, Jim Friedland, Director of Investor Relations. Please go ahead.\\n\\nJim Friedland\\n\\nThank you. Good afternoon, everyone, and welcome to Alphabet's third quarter 2023 earnings conference call. With us today are Sundar Pichai, Philipp Schindler and Ruth Porat.\\n\\nNow, I'll quickly cover the safe harbor. Some of the statements that we make today regarding our business operations and financial performance may be considered forward-looking. Such statements are based on current expectations and assumptions that are subject to a number of risks and uncertainties. Actual results could differ materially. Please refer to our Form 10-K, including our Risk Factor section and our Form 10-Qs. We undertake no obligation to update any forward-looking statement.\\n\\nDuring this call, we will present both GAAP and non-GAAP financial measures. A reconciliation of non-GAAP to GAAP measures is included in today's earnings press release, which is distributed and available to the public through our investor relations website located at abc.xyz/investor. Our comments will be on year-over-year comparisons unless we state otherwise.\\n\\nAnd now, I'll turn the call over to Sundar.\\n\\nSundar Pichai\\n\\nThank you, Jim, and hello, everyone. I'm pleased with our business results this quarter, which demonstrates strong growth in Search and YouTube and momentum in Cloud. Google turned 25 in September, which offered an opportunity to reflect on our progress over the last quarter century and to look ahead to the opportunities enabled by AI we are so excited and confident about.\\n\\nOur product momentum continued this quarter, as you saw with Cloud Next, Made on YouTube and Made by Google. It's all part of our focus on making AI more helpful for everyone, and we are making good progress across the four areas that we shared last quarter. First, improving knowledge and learning. This includes our work with the Search Generative Experience, which is our experiment to bring Generative AI capabilities into Search. We have learned a lot from people trying it, and we have added new capabilities, like incorporating videos and images into responses and generating imagery. We've also made it easier to understand and debug generated code.\\n\\nDirect user feedback has been positive with strong growth and adoption. In August, we opened up availability to India and Japan with more countries and languages to come. As we add features and expand into new markets, we are engaging with the broader ecosystem and will continue to prioritize approaches that add value for our users, send valuable traffic to publishers, and support a healthy open Internet. With Generative AI applied to Search, we can serve a wider range of information needs and answer new types of questions, including those that benefit from multiple perspectives. We are surfacing more links with SGE and linking to a wider range of sources on the results page, creating new opportunities for content to be discovered.\\n\\nOf course, ads will continue to play an important role in this new Search experience. People are finding ads helpful here as they provide useful options to take action and connect with businesses. We'll experiment with new formats native to SGE that use Generative AI to create relevant high-quality ads customized to every step of the Search journey.\\n\\nThe second area we are focused on is boosting creativity and productivity. Bard is particularly helpful here. It's a direct interface to a conversational LLM, and we think of it as an early experiment and complementary experience to Google Search. Bard can now integrate with Google apps and services, showing relevant information from Workspace, Maps, YouTube, and Google Flights and Hotels. We've also improved the Google it feature. It provides other sources to help people evaluate Bard's responses and explore information across the web.\\n\\nEarlier this month, we announced Assistant with Bard, a personal assistant powered by Generative AI. It combines Bard's generative and reasoning capabilities with Assistant's personalized help. You can interact with it through text, voice, or images, and in the coming months, you'll be able to opt in on Android and iOS mobile devices. Our collaborative tools in Workspace and YouTube are also part of how we boost creativity and productivity, and they are seeing great initial traction.\\n\\nThird, we are enabling developers, businesses, and other organizations to build their own transformative products and services. For example, thousands of customers and partners are already using Google Cloud to capture the potential of AI and we'll share more there in a minute.\\n\\nAnd fourth, we are building and deploying AI responsibly, so that everyone can benefit. One area we are focused on is making sure people can more easily identify when they are encountering AI-generated content online. Using new technology powered by Google DeepMind SynthID, images generated by Vertex AI can be watermarked in a way that is invisible to the human eye without reducing the image quality. Underlying all this work is the foundational research done by our teams at Google DeepMind and Google Research. We are excited to roll out more of what they've been working on soon.\\n\\nAs we expand access to our new AI services, we continue to make meaningful investments in support of our AI efforts. We remain committed to durably re-engineering our cost base in order to help create capacity for these investments in support of long-term sustainable financial value. Across Alphabet, teams are looking at ways to operate as effectively as possible focused on their biggest priorities.\\n\\nTurning next to YouTube, which saw solid momentum in both its ads and subscription businesses in Q3. NFL Sunday Ticket is now live and receiving excellent reviews. Fans love our multi-view feature, which can live stream up to four games on a single screen. Weâ€™ve heard positive feedback from our partners at the NFL about the new features and live stream reliability. This is a clear example of our ability to execute big partnerships with excellence and at scale.\\n\\nI'm really pleased with the growth and engagement on YouTube Shorts. We continue to work on closing the monetization gap here. Shorts now average over 70 billion daily views and are watched by over 2 billion signed-in users every month. At Made on YouTube in September, we announced new tools that make it easier to create engaging content. Dreamscreen is an experimental feature that allows creators to add AI-generated video or image backgrounds to shorts. And YouTube Create is a new mobile app with a suite of production tools for editing shorts, longer videos, or both.\\n\\nNext, Google Cloud. We see continued growth with Q3 revenue of $8.4 billion, up 22%. Today, more than 60% of the world's 1,000 largest companies are Google Cloud customers. At Cloud Next, we showcased amazing innovations across our entire portfolio of infrastructure, data and AI, workspace collaboration, and cybersecurity solutions. We offer advanced AI-optimized infrastructure to train and serve models at scale. And today, more than half of all funded Generative AI startups are Google Cloud customers. This includes AI21 Labs, Contextual, Elemental Cognition, Rytr, and more.\\n\\nWe continue to provide the widest choice of accelerator options. Our A3 VMs powered by NVIDIA's H100 GPU are generally available, and we are winning customers with Cloud TPU v5e, our most cost efficient and versatile accelerator to date. On top of our infrastructure, our Vertex AI platform helps customers build, deploy, and scale AI-powered applications. We offer more than 100 models, including popular third-party and open source models, as well as tools to quickly build, search, and conversation use cases. From Q2 to Q3, the number of active Generative AI projects on Vertex AI grew by 7x, including Highmark Health, which is creating more personalized member materials.\\n\\nDuet AI was created using Google's leading large foundation models and especially trained to help users to be more productive on Google Cloud. We continue expanding its capabilities and integrating it across a wide range of cloud products and services. With Duet AI, we are helping leading brands like PayPal and Deutsche Bank boost developer productivity. And we are enabling retailers like Aritzia and Gymshark to gain new insights for better and faster business results. In fact, companies are increasingly using AI for the purpose of analyzing data. And customers are choosing Google Cloud because we are the only large cloud provider with a unified platform to analyze structured and unstructured data. In Workspace, thousands of companies and more than a million trusted testers have used Duet AI. They are writing and refining content in Gmail and Docs, creating original images from text within slides, organizing data in Sheets and more. These innovations enable us to provide new services and grow our base of 10 million paying customers, including enterprises like Grupo Boticario, Unilever and Warner Music.\\n\\nWe also integrated Duvet AI across our cybersecurity portfolio to differentiate in the marketplace, providing Generative AI-powered assistance in Mandiant Threat Intelligence, Chronicle Security Operations, and Security Command Center. This reduces the time security teams spend writing, running, and refining searches by seven times. We are the only leading security provider that combines frontline intelligence and expertise, a modern security operations platform, and a trusted cloud foundation, all infused with Generative AI, helping protect customers and partners like BT, Jack Henry & Associates, and CoverMyMeds.\\n\\nTurning to hardware. We unveiled our new products this month. We introduced our new Pixel 8, Pixel 8 Pro, and Pixel Watch 2 to very positive consumer feedback and reviews. Pixel is the fastest growing smartphone brand in our top markets and the only one that grew in units sold year-over-year. Our portfolio of Pixel products are brought to life, thanks to our combination of foundational technologies, AI, Android, and Google Tensor. Google Tensor G3 is the third generation of our tailor-built chip. It's designed to power transformative experiences by bringing the latest in Google AI research directly to our newest phones. A new AI-powered editing features in Google Photos on Pixel 8 and Pixel 8 Pro remove distractions, generate the best shot from multiple images and reduce distracting sounds in videos.\\n\\nPixel and our third-party ecosystem are powered by Android. We just released Android 14 with more accessibility features. I also want to mention Chromebook Plus, a new category which provides the best of Chrome on great hardware with built-in Google Apps and powerful AI capabilities. We also shared that Chromebooks will now get regular automatic updates for 10 years, more than any other operating system.\\n\\nIn Other Bets, Waymo is onboarding more riders to its commercial ride hailing service as it gradually adds over 100,000 people from its San Francisco waitlist. Austin will follow as its next ride hail city. Wing and Walmart announced a new partnership to provide drone delivery service in the Dallas-Fort Worth area.\\n\\nBefore handing over to Philipp, I want to thank our employees around the world who are working to create innovative products and provide great services to people and businesses who use our products. Philipp?\\n\\nPhilipp Schindler\\n\\nThanks, Sundar, and hi, everyone. I'll start with our performance for the quarter and then give color into the three key priority areas for ads. Google AI, Retail and YouTube that we've identified on past calls as opportunities for long-term growth in advertising. Google Services revenues of $68 billion were up 11% year-on-year.\\n\\nIn Google Advertising, Search and Other, revenues grew 11% year-on-year, led by solid growth in the Retail vertical. In YouTube Ads, revenues were up 12% year-on-year, driven by growth in both brand and direct response. In Network, revenues declined 3% year-on-year. Google Other revenues were up 21% year-on-year, led by strong growth in YouTube subscription revenues.\\n\\nLet's start with Google AI. Recent dramatic advances in everything from foundational research models to LLM to Generative AI are improving our ability to deliver better performance and profitability for advertisers and more helpful, delightful experiences for users. We covered many innovations last quarter after GML, like our conversational experience in Google Ads, significant updates to Performance Max and new campaign types like Demand Gen. And as Sundar said, we're continuing to experiment with new ad formats on SGE. It's extremely important to us that in this new experience, advertisers still have the opportunity to reach potential customers along their Search journeys. I'll highlight more ways we're innovating with the best of Google AI as we double-click into our core business.\\n\\nIn Retail, we had a great quarter. In a market where every dollar counts, our proven AI-powered solutions like Search and PMax are helping retailers drive reliable, strong ROI and meet customers wherever they are across the funnel. In Q3, we also started prepping retailers for what will be a long holiday season.\\n\\nLet me share some things. Number one, with a maximum number of days between Thanksgiving and Christmas and expectations for many micro peaks beyond Cyber-Five, we're arming businesses with insights and planning tools, including OptiScore and Performance Planner to uncover new opportunities, plan budgets and targets to stay competitive and be smarter with their inventory and pricing strategy.\\n\\nNumber two. Consumer expectations are shifting, especially around price and convenience. We've seen 4x deals queries during the holidays versus other periods. 75% of users say they'll shop with those offering free shipping. Retailers are capitalizing on these trends with our differentiated merchant offerings like merchant promotions and fulfillment options. And we're making improvements to significantly boost the number of deals shown to shoppers in Search this holiday season. Look out for more in the coming days about new ways we'll help shoppers browse deals across the web this year.\\n\\nNumber three. No surprise, omni-channel is the way to succeed. With our suite of omni product solutions, including local inventory ads, omnibidding, and PMax for store goals, retailers big and small, are capturing demand and incremental store budgets while engaging with high value customers. Innovation continues across our shopping and merchant experiences powered by Google AI. Our virtual try-on tool for apparel launched in June and has been a hit with consumers and brands. Users engage with virtual try-on images at a higher rate versus regular brand provided images.\\n\\nProduct Studio is another launch from GML getting positive feedback in pilot mode. It uses the best of Gen.AI to help businesses create unique and tailored imagery for free that they can then scale across their channels. We're seeing early merchant testers using it to seasonalize their content for the holidays.\\n\\nLet's shift to YouTube. It's worth repeating, our intense focus on creator success coupled with our multi-format strategy are at the center of how we think about YouTube's long-term growth. Shorts, connected TV and our subscription offerings are key drivers here and we're investing across each to solidify YouTube's position as the best place to create, the best place to watch and the best place to deliver results.\\n\\nSundar mentioned watch time and engagement momentum on shorts as well as our monetization progress. He also covered subscription growth and NFL Sunday Ticket. As for connected TV, we continue to be the number one overall streaming destination according to Nielsen. 150 million plus people are watching YouTube on CTV screens every month in the US. Whether it's music videos, NFL Sunday Ticket, free movies, shorts, a continuous stream of MrBeast or some other creator-led content, viewers want choice and variety, and we're giving it to them all in one place. And to help creators and advertisers connect with these billions of viewers across moments, screens, and formats, we're bringing Google AI to awesome new creation tools and ad solutions.\\n\\nAI will do wonders for creation and storytelling. From Dreamscreen and YouTube Create, which Sundar talked about, to features that audit up content in multiple languages, flip and trim existing assets, remix and clip videos, and more, we're just getting started. We're also helping brands break through at speed and scale across the funnel to drive results. Spotlight Moments launched last week. It uses AI to identify trending content around major cultural moments for brand sponsorship opportunities. There's video reach campaigns, which are expanding to in-feed and shorts and will be generally available in November. AI is helping advertisers find as many people as possible in their ideal audience for the lowest possible price. Early tests are delivering 54% more reach at 42% lower cost.\\n\\nAnd then with video view campaigns, AI is serving skippable ads across in-stream, in-feed, and shorts and helping advertisers earn the maximum number of views at the lowest possible cost. So far, they're driving 40% more views on average versus in-stream alone. Then for YouTube and other feed-based services, there's our new Demand Gen campaign, which launched in April, rolled out worldwide last week, and was designed for the needs of today's social marketers to engage people as they stream, scroll and connect. It combines video and image ads in one campaign with access to 3 billion users across YouTube and Google, and the ability to optimize and measure across the funnel using Google AI. Demand Gen is already driving success for brands like Samsung and Toyota.\\n\\nBefore I wrap, one quick highlight on our close collaboration and commitment to our most important ecosystems and partners. In July, we launched Google News Showcase in the US, our curated online news experience and licensing program with more than 150 news publications, 90% of which are local or regional. Globally, over 2,500 news publications have signed onto News Showcase, and the product is live in 23 countries today. Our commitment to open access to news and information remains strong.\\n\\nWith that, I'll end with a thank you to our customers and partners around the world for their continued trust and collaboration, and our Googlers everywhere for their incredible hard work and dedication. Ruth, over to you.\\n\\nRuth Porat\\n\\nThank you, Philipp. We are very pleased with our financial results for the third quarter, driven by meaningful growth in Search and YouTube and momentum in Cloud. My comments will be on year-over-year comparisons for the third quarter, unless I state otherwise.\\n\\nI will start with results at the Alphabet level followed by segment results and conclude with our outlook. For the third quarter, our consolidated revenues were $76.7 billion, up 11% in both reported and constant currency. Search remained the largest contributor to revenue growth. In terms of expenses, total cost of revenues was $33.2 billion, up 7%, primarily reflecting other cost of revenues of $20.6 billion, which was up 6%. Growth here was primarily driven by content acquisition costs mainly for YouTube subscription offerings. As noted in our earnings release, the overall increase in data center and other operations costs was partially offset by a reduction in depreciation expense due to the change in estimated useful lives we made starting in the first quarter of the year.\\n\\nOperating expenses were $22.1 billion, up 6% reflecting the following. First, an increase in R&D expenses, driven primarily by compensation. Second, an increase in G&A expenses, reflecting the impact of charges related to legal matters. And finally, sales and marketing expenses, which were relatively flat to last year.\\n\\nOperating income was $21.3 billion, up 25%, and our operating margin was 28%. Other income and expense was a loss of $146 million. Net income was $19.7 billion. This reflects an effective tax rate of 7% in the third quarter from an IRS change related to the use of foreign tax credits, which had an outsized impact on the third quarter rate because the change resulted in a catch-up for prior periods.\\n\\nWe delivered free cash flow of $22.6 billion in the third quarter and $78 million for the trailing 12 months. We ended the quarter with $120 billion in cash and marketable securities. As a reminder, our cash balance and free cash flow in the second and third quarters benefited from the deferral of certain tax payments to the fourth quarter of 2023.\\n\\nAs noted in our earnings release, on October 16, we made an estimated tax payment of $10.5 billion related to this deferral, which will be reflected in our cash balance and free cash flow in the fourth quarter.\\n\\nTurning to segment results. Within Google Services, revenues were $68 billion, up 11%. Google Search and other advertising revenues of $44 billion in the quarter were up 11%, led again by growth in retail. YouTube advertising revenues of $8 billion were up 12%, driven by both brand advertising and direct response. Network advertising revenues of $7.7 billion were down 3%. Other revenues were $8.3 billion, up 21%, primarily reflecting growth in YouTube non-advertising revenues driven by subscriber growth in YouTube TV followed by YouTube Music Premium. TAC was $12.6 billion, up 7%. Google Services operating income was $23.9 billion, up 27% and the operating margin was 35%.\\n\\nTurning to the Google Cloud segment. Revenues were $8.4 billion for the quarter, up 22%. GCP revenue growth remained strong across geographies, industries and products, although the Q3 year-on-year growth rate reflects the impact of customer optimization efforts. Google Workspace also delivered strong revenue growth, primarily driven by increases in average revenue per seat. Google Cloud had operating income of $266 million, and the operating margin was 3%. As to our Other Bets, for the third quarter, revenues were $297 million and the operating loss was $1.2 billion.\\n\\nTurning to our outlook for the business. With respect to Google Services. First, within advertising. After a period of historic volatility, we were pleased with the year-on-year revenue growth of Search and YouTube advertising in the third quarter. Second, within other revenues, in our YouTube subscription products the substantial growth in revenues primarily reflects subscriber growth. Looking ahead, a full quarter of NFL Sunday Ticket revenues as well as associated content acquisition costs will be reflected in Q4 results compared to only a few weeks in the third quarter.\\n\\nPlay had growth in the third quarter, driven primarily by an increase in the number of buyers. With respect to hardware, there is a headwind to revenues in the fourth quarter, reflecting efforts to optimize the portfolio with tighter targeting of our go-to-market investments as well as the ongoing impact from the difference in launch timing for the Pixel 6a and 7a that we mentioned last quarter.\\n\\nTurning to Google Cloud. We are pleased with the ongoing customer engagement with GCP and Workspace and the potential benefit of our AI solutions including infrastructure and services such as Vertex AI and Duet. We continue to invest aggressively given the significant potential we see while remaining focused on profitable growth. In terms of expenses and profitability, we're pleased with our operating performance. As we have repeatedly stressed, we remain focused on durably reengineering our cost base to create investment capacity to support our growth priorities, most important of which is with AI.\\n\\nWe have a number of workstreams in place. First, we are maintaining a slower pace of headcount growth, reflecting product prioritization and reallocation of talent to support our most important growth opportunities. Second, we remain focused on optimizing our real estate footprint, including how and where we work to reduce our expense growth. As you can see from our earnings release, we incurred $207 million in accelerated rent and depreciation in the third quarter related to these actions. Third, we have engineering work streams underway to improve productivity across Alphabet. Given the magnitude of investment in our technical infrastructure, we have a superb team focused on efficiency of our operations there. We are also making progress in streamlining operations across Alphabet through the use of AI. Finally, there are ongoing workstreams that are improving the efficiency of our spend with suppliers and vendors through our central procurement organization. And to be clear, across the portfolio of other bet companies, we have also been working to identify opportunities to create sharper focus and to operate more efficiently and effectively.\\n\\nWith respect to sequential quarter-on-quarter trends, two further points. First, cost of sales in the fourth quarter will reflect both higher hardware costs given Pixel family launches as well as increased CAC for YouTube as previously noted. Second, as usual, we expect sales and marketing expenses to be more heavily weighted to the end of the year, in part to support product launches in the holiday season. Finally, our reported CapEx in Q3 was $8 billion, driven overwhelmingly by investment in our technical infrastructure with the largest component for servers, followed by data centers, reflecting a meaningful increase in our investments in AI compute.\\n\\nThe growth in reported cash CapEx in Q3 is somewhat muted due to the timing of supplier payments, which can cause variability from quarter-to-quarter. We continue to invest meaningfully in the technical infrastructure needed to support the opportunities we see in AI across Alphabet and expect elevated levels of investment, increasing in the fourth quarter of 2023 and continuing to grow in 2024.\\n\\nIn closing, we remain very excited about the opportunities ahead and committed to deliver sustainable financial value. Thank you. Sundar, Philipp and I will now take your questions.\\n\\nQuestion-and-Answer Session\\n\\nOperator\\n\\n[Operator Instructions] And our first question comes from Brian Nowak with Morgan Stanley. Your line is open.\\n\\nBrian Nowak\\n\\nGreat. Thanks for taking my question. I have two. The first one, maybe a sort of a jump ball. There's somewhat of an investor debate about sort of the incremental return on capital to Search when it comes to AI. I know it's early, but are there any examples that you're seeing with SGE or Bard on higher utility, higher conversion rates, more engagement, just something to sort of show signal around the return that could come from these investments? And the second one, Ruth, I know you've spoken a lot about durably reengineering the cost base. I think in the past, you've talked about how expenses could grow slower than revenue in 2024. Is that sort of still the high-level way to think about it or is that potentially changing a bit as investments are continuing? Thanks.\\n\\nSundar Pichai\\n\\nRuth, do you want to take the second part?\\n\\nRuth Porat\\n\\nSure. Thanks for that, Brian. So overall, that's sort of a truism as you know well, that looking to grow revenues at a faster rate than expenses as we're focused on delivering sustainable financial value. And so that really takes us to the work streams, which I tried to tick through, again, those remain the driver. They're the real priority there -- those are the efforts that are going to enable us to expense growth as moderated as possible while supporting the investment growth that is so exciting in front of us, in particular, around AI.\\n\\nSundar Pichai\\n\\nAnd to your first part, obviously, we see AI as a foundational platform shift and are excited about the opportunities across our business. It starts with Search. And I've been pretty pleased with how the user feedback has been on SGE. We are rolling it out to more users. Through it all, we are making sure the product works well, and we are generating value for our ecosystem, and that adds transition as well. And I think I view this is, with AI, the opportunity to evolve Search and Assistant over the next decade ahead. And I think as we've always seen, when you continue to invest and build great experiences, you can get value on the other side. And I do think over time, there will be newer pads, just like we have done on YouTube, I think with the AI work that are subscription models is a possible path as well. And obviously, all of the AI investments we are doing applies across Cloud, too, and I'm pretty optimistic about what's ahead there as well.\\n\\nBrian Nowak\\n\\nGreat. Thank you, both.\\n\\nOperator\\n\\nYour next question comes from Doug Anmuth with JPMorgan. Your line is open.\\n\\nDoug Anmuth\\n\\nThanks for taking the questions. One for Sundar and one for Ruth. Just, Sundar, you talked a lot about AI. I was hoping you could talk more about Gemini and how we'll differentiate from other models, some of the multimodal capabilities and what new experiences or agents do you think it could unlock and how we should think about timing? And then also just on Cloud, I hope you can talk about some of the factors there on the decel in Cloud and just what you're seeing in terms of optimizations? And is there any sign of new workload deployments taking place? Thanks.\\n\\nSundar Pichai\\n\\nThanks. Good questions. On Gemini, obviously, it's effort from our combined Google DeepMind team. I'm very excited at the progress there and as we're working through getting the model ready. To me, more importantly, we are just really laying the foundation of what I think of as the next generation series of models we'll be launching throughout 2024. The pace of innovation is extraordinarily impressive to see. We are creating it from the ground-up to be multimodal, highly efficient tool and API integrations and more importantly, laying the platform to enable future innovations as well. And we are developing Gemini in a way that it is going to be available at various sizes and capabilities, and we'll be using it immediately across all our products internally as well as bringing it out to both developers and cloud customers through Vertex. So I view it as a journey and each generation is going to be better than the other, and we are definitely investing and the early results are very promising. On Cloud, maybe what I would say is, overall, we had definitely started seeing customers looking to optimize spend. We leaned into it to help customers given some of the challenges they were facing. And so that was a factor. But we are definitely seeing a lot of interest in AI. There are many, many projects underway now, just on Vertex alone, the number of projects grew over 7x. And so we see signs of stabilization, and I'm optimistic about what's ahead.\\n\\nDoug Anmuth\\n\\nThank you, Sundar.\\n\\nOperator\\n\\nYour next question comes from Eric Sheridan with Goldman Sachs. Your line is now open.\\n\\nEric Sheridan\\n\\nThank you, sir, very much for taking the questions. Two, if I could. Sundar, you guys led over a year ago, starting with Performance Max. And I wanted to know if we could get your updated thoughts on how AI might impact the broader advertising industry and how you're aligning Alphabet in Google's goals with AI and where it might take the advertising industry in the years ahead? That would be the first question. And then about a year ago, Philipp and Ruth started talking about some of the brand advertising headwinds that YouTube was facing. As we start to lap those headwinds, how should we be thinking about a broad recovery in brand advertising versus elements of still headwinds that are being faced in the broader ad space, specifically with YouTube? Thank you.\\n\\nPhilipp Schindler\\n\\nSo maybe I take the first one. We're very pleased with how Performance Max is performing. It gives advertisers really maximum performance across all inventory from, one, really AI-powered campaign, and it's probably the ultimate example of AI in action across our ads product. It's delivering excellent ROI. Those using it achieve like on average, over 18% more conversions at a similar cost per action. So since rolling it out about two years ago, we've continued to expand the features, give advertisers additional ways to steer how it works. There are a lot of things like account level, negative keywords, other details here. We launched new life cycle goals, customer life cycle goals, we call them revamped asset creation flow. That really helps business adapt and scale the most successful creatives. I think that's one to watch.\\n\\nWe will also continue to build other new PMax features based on all the advertiser feedback we're seeing. So we're very, very encouraged by the progress here. Overall, maybe there was a second part to your question a bit on what we're hearing from the customers out there, look, driving ROI and efficiency is still top of mind for many, right? It's a rapidly shifting and still quite unpredictable consumer landscape out there. Our AI tools are very well received. AI, Gen AI are top of mind for everybody, really. There's a ton of excitement, lots of questions about it. Many understand the value. Nearly 80% of our advertisers already use at least one AI-powered search ads product. And yeah, we're hearing a lot of good feedback on, number one, our ads AI essentials, which are really helping to unlock the power of AI and set up for durable ROI growth on the advertiser side. This is -- those are products like the foundation for data and measurement, things like Google Tag, Consent Mode and so on. And obviously, Search and PMax we talked about it and then all the Gen AI products, all those different ones. So there's a whole lot of interest in those products, yeah.\\n\\nRuth Porat\\n\\nAnd then on to your second question regarding YouTube, as we said, overall year-on-year growth in revenues was driven by both brand advertising and direct response. But very much to your question, yes, there was a stabilization in spending by advertisers. We're really pleased about that. We're particularly pleased about the ongoing performance in the Living Room and on Shorts. And as I said, that's both watch time growth and monetization I'd say the other thing benefiting YouTube is the retail strength we talked about with Search, retail strength in APAC in both Search and YouTube, and that really began in the second quarter, continued in the third quarter, but that was another contributor. So quite a number of things going on. I feel good about the results the team was able to deliver here.\\n\\nEric Sheridan\\n\\nThank you so much.\\n\\nOperator\\n\\nYour next question comes from Lloyd Walmsley with UBS. Your line is open.\\n\\nLloyd Walmsley\\n\\nGreat. Thanks for taking the question. Two, if I can, First, as we just think about the rollout of SGE across the user base, like how far along is that? And how do you balance the product rollout and consumer uptake versus monetization in that transition? And then the second one, also sort of Generative AI related. How quickly are you guys finding new ways of optimizing whether that's shrinking model sizes, chip efficiencies or anything else? And do you think overall capital intensity of the business scales up or do you just find ways to do this more efficiently as usage scales? Anything you could share there would be great. Thanks.\\n\\nSundar Pichai\\n\\nOn the first part about SGE, we are still in a very -- very early days in terms of how much we have rolled it out, but we have definitely gotten it out to enough people in both geographically across user segments and enough to know that the product is working well. It improves the experience and -- but there are areas to improve, which we are fine tuning. Our true north here is getting at the right user experience we want to and pretty comfortable seeing the trajectory. And we've always worked through these transitions, be it from desktop to mobile, or from now mobile to an AI-enhanced experience. And so it's nothing new, and I feel very comfortable that as we go through it, the strength of our teams, both on the organic side as well as ad side to drive the right experience for users, including ads will pay dividends.\\n\\nSo -- and I think we'll continue to make improvements and make progress there. On your second question, at a high level, I would say, all through the -- we just celebrated 25 years and of all the things I was proud about when I looked at the strength of the work we have done across our infrastructure as a company, our technical infrastructure as a company and various given stages at a given moment in time, when we adopted new generations of technology, we have looked at the cost of it. But then the curves, the efficiency curves we have driven on top of it has always been phenomenal to see. And I see the current moment is no different. Already through this year, we are driving significant efficiencies, both in our models, in training costs and serving costs and our ability to adapt what's needed to the right use case. And so I think we'll do everything that is needed to make sure we have the leading AI models and infrastructure in the world, bar none, and will continue driving efficiencies from there.\\n\\nLloyd Walmsley\\n\\nOkay. Thank you.\\n\\nOperator\\n\\nYour next question comes from Michael Nathanson with MoffettNathanson. Your line is now open.\\n\\nMichael Nathanson\\n\\nThank you. I'm going to ask you guys a multipart question on YouTube TV. So firstly, what were the broader objectives for getting Sunday Ticket? How does it perform versus those objectives? What lessons have you learned from having the NFL Sunday Ticket and how does that affect your appetite for more sports going forward? Thanks.\\n\\nPhilipp Schindler\\n\\nSo, as Sundar said earlier, we're several weeks into our first season, and we're very pleased with how it's going, I think, in the broader context, you have to look at it as overall a YouTube subscription strategy. The great feedback we've gotten so far on the YouTube experience is very, very significant. People love the navigation. They love multi-view, they love the chats and the poles and frankly, people are very happy with the lack of latency here. The number one piece of concrete feedback the team has gotten is actually that people want the ability to pick their own games from multi-view which is -- multi-view is the awesome feature, we started rolling out on YouTube TV that gives fans the ability to basically watch multiple streams here at once. And yeah, overall, the teams are working hard to build a fantastic experience, and we are really trying to stay focused on getting our first season right and providing the best possible experience really for fans here.\\n\\nMichael Nathanson\\n\\nThank you.\\n\\nOperator\\n\\nYour next question comes from Justin Post with Bank of America. Your line is now open.\\n\\nJustin Post\\n\\nGreat. Thanks. A couple of questions on Q4. Can you provide any color on if there's been any pause in advertising around the Middle East conflict in October, anything we should be aware of for Q4? And then second, when we do think about the Sunday Ticket impact, I know you can't give us revenues or expenses, but overall, would that be a headwind to margins in Q4 or something we should be thinking about? Thank you.\\n\\nRuth Porat\\n\\nSo, look, on your -- on the first question, obviously, this is a tragic, tragic -- there are no words to talk about what's going on. And all of our focus has been on supporting our people there and how our products can be as helpful as possible in this very painful time, broadly. And so nothing really to add.\\n\\nAnd then in terms of the second question, Sunday Ticket, the only thing I tried to call out there is that clearly, this is the first full quarter of Sunday Ticket that is contributing overall to the subscription revenues that we see. That's in part of other revenues also, obviously, is contributing to higher CAC in the fourth quarter. So try to make that really clear. And as we look longer term, we expect to generate an attractive return over the life of the deal. We're continuing to invest in support of this and excited about the additional opportunities that come out of it, working with partners to deliver clips and other opportunities.\\n\\nAs we've said, we've heard positive feedback from our partners at the NFL about the new features and live stream reliability. And this is really a clear example of our ability to execute big partnerships with excellence at scale and really leverage a lot of the extraordinary magic at YouTube and across Google, and that's what we're excited about.\\n\\nJustin Post\\n\\nGreat. Thank you.\\n\\nOperator\\n\\nYour next question comes from Ken Gawrelski with Wells Fargo. Your line is now open.\\n\\nKen Gawrelski\\n\\nThank you so much. Two questions, if I may. First, how do you think about the future -- the future structure of AI-driven search capabilities? Will activity remain centralized in a Search bar or will it be decentralized and present in many different applications, including on third-party applications? You alluded to Bard being integrated into multiple Google experiences early in the call. And then the second question is, any update on the Chrome cookie deprecation plan to begin in 1Q '24. What have you seen so far based on your early testing of privacy sandbox and what advertiser feedback have you received?\\n\\nSundar Pichai\\n\\nOn your first question, look, I broadly think of it as people are looking for information. They always look for it in many, many different ways. We've given the product search example. People can directly go to Amazon as an example or come to Google. So if you zoom back and take an information view of the world, there's always been many different ways to get it. And part of our work we do in making Search be world-class and give users what they're looking for so that we can get it as much of that intent as possible. So I don't see that changing. With mobile, there were more ways people could get information, but we worked out to make Search work better in the mobile world. And similarly, a view with AI, there'll be many ways people get information, but it also offers us an opportunity in Search and in Assistant to take it to the next level and answer use cases, which we couldn't have done before and expand the diverse set of needs where we are sourced. So that's how I see the opportunity ahead.\\n\\nPhilipp Schindler\\n\\nAnd to the second part of your question, yes, Chrome still plans to begin phasing out third-party cookies in the second half of '24. In the last several months, Chrome has really made significant progress on the privacy sandbox with APIs for developer testing, and they're not generally available in Chrome. Our ads team is testing these APIs. And as we shared back in April, the preliminary results of our interspace ads testing showed that a combination of what we call privacy preserving signals and AI optimization actually provides positive results for businesses preparing for a cookie-less future. We also recently announced that in Q1 of '24, we plan to deprecate third-party cookies for 1% of Chrome users, and this will support developers, obviously, in conducting their real-world experiments to assess the readiness and effectiveness of their products in this -- without third-party cookies. And we're overall encouraged by the ecosystem engagement on privacy sandbox. We'll continue to work with the industry and regulators in how these technologies can support the transition to, frankly, a more private web.\\n\\nKen Gawrelski\\n\\nThank you.\\n\\nOperator\\n\\nAnd our last question comes from Mark Mahaney with Evercore. Your line is now open.\\n\\nMark Mahaney\\n\\nThank you. Two questions, please. Ruth, you talked about these elevated levels of investments in Q4 and in '24. I'm sorry, were you referring to just CapEx or CapEx and total expenses? And then on the comments around stabilization in Cloud, is this something that you just started to see in the September quarter? Or had you seen that starting earlier in the year? And if you just started seeing in the September quarter, would you have any thoughts on why you would have seen it like Google Cloud would have seen it maybe later than some of the other hyperscalers? Thank you.\\n\\nRuth Porat\\n\\nSo I think what you're referring to is my CapEx comment. I was trying to make the point that we are committed to meaningfully investing in CapEx, given all the opportunities we see. We do continue to expect elevated levels of investment in our technical infrastructure. It it will be increasing in the fourth quarter and talked about some of the difference in timing, muted timing in the third quarter due to the timing of supplier payments and then try to make it clear that we will continue to grow CapEx in 2024 or more specifically to your question, 2024 aggregate CapEx will be above the full year 2023. So that was the main one.\\n\\nAnd then as it relates to Cloud, as Sundar said, what we're really excited about is the revenue growth does reflect healthy customer adoption across the portfolio, and that's infrastructure, data analytics, security. And so weâ€™re -- I can't comment on others, but we feel good about where we're sitting here and looking forward, and we'll let you do the forecasting. DCP growth in the third quarter was above the growth rate for Cloud overall, and we feel really good about the work that they're doing there. And then, of course, in addition to that is all of the contribution from Google Workspace.\\n\\nMark Mahaney\\n\\nThank you.\\n\\nOperator\\n\\nThank you. And that concludes our question-and-answer session for today. I'd like to turn the conference back over to Jim Friedland for any further remarks.\\n\\nJim Friedland\\n\\nThanks, everyone, for joining us today. We look forward to speaking with you again in our fourth quarter 2023 call. Thank you, and have a good evening.\\n\\nOperator\\n\\nThank you, everyone. This concludes today's conference call. Thank you for participating. You may now disconnect.\\n\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   $ % & ' ( ) , - . / 0 1 2 3 4 5 6 7 8 9 : ? A B C D E F G H I J K L M N O P Q R S T U V W Y [ ] a b c d e f g h i j k l m n o p q r s t u v w x y z â€™\n",
      "77\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(input)))\n",
    "vocab_size = len(chars)\n",
    "print(' '.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "\n",
    "encode = lambda s : [ stoi[c] for c in s]\n",
    "decode = lambda i : [ ''.join(itos[i] for i in i)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31, 58, 58]\n",
      "['Hii']\n"
     ]
    }
   ],
   "source": [
    "print(encode(\"Hii\"))\n",
    "print(decode([31, 58, 58]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating tensors for the text using Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([46962]) <built-in method type of Tensor object at 0x1343cd7f0>\n",
      "tensor([24, 61, 65, 57, 50, 51, 54, 69,  1, 32, 63, 52, 10,  1,  6, 37, 24, 42,\n",
      "        27, 24, 40, 22, 30, 38, 38, 30,  7,  1, 40, 15,  1, 14, 12, 14, 15,  1,\n",
      "        28, 50, 67, 63, 58, 63, 56, 68,  1, 26, 50, 61, 61,  1, 43, 67, 50, 63,\n",
      "        68, 52, 67, 58, 65, 69,  1, 38, 52, 69, 64, 51, 54, 67,  1, 14, 16,  8,\n",
      "         1, 14, 12, 14, 15,  1, 16, 22, 15, 12,  1, 39, 36,  1, 28, 43,  0,  0,\n",
      "        26, 64, 62, 65, 50, 63, 74,  1, 39, 50])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.tensor(encode(input), dtype= torch.long)\n",
    "print(data.shape, data.type)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting dataset into train and Validationj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(len(input)*0.9)\n",
    "train = data[:n]\n",
    "val = data[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a blocksize context and target data set\n",
    "### When we give a context the model has to predict the target\n",
    "### The input output model is a sequential model\n",
    "### a->b, a,b ->c, a,b,c -> d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([24, 61, 65, 57, 50, 51, 54, 69,  1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8 ## taking block size of 8\n",
    "train[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When context is tensor([24]) then 61\n",
      "When context is tensor([24, 61]) then 65\n",
      "When context is tensor([24, 61, 65]) then 57\n",
      "When context is tensor([24, 61, 65, 57]) then 50\n",
      "When context is tensor([24, 61, 65, 57, 50]) then 51\n",
      "When context is tensor([24, 61, 65, 57, 50, 51]) then 54\n",
      "When context is tensor([24, 61, 65, 57, 50, 51, 54]) then 69\n",
      "When context is tensor([24, 61, 65, 57, 50, 51, 54, 69]) then 1\n"
     ]
    }
   ],
   "source": [
    "x = train[:block_size]\n",
    "y = train[1:block_size+1]\n",
    "\n",
    "for i in range(block_size):\n",
    "    context = x[:i+1]\n",
    "    target = y[i]\n",
    "\n",
    "    print(f'When context is {context} then {target}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating batches of the input(context) and output(target) data\n",
    "#### We want to make use of teh parallel processing computing power of GPUs\n",
    "#### We will create the single stack of the block sized data into multiple chunks of batch size data\n",
    "#### Lets say we have 96 we will split them first into block size data of 8(block size)*12\n",
    "#### now we will split the data onto chunks of batches of size lets say 4 \n",
    "#### This becomes three batches of data => 8* 3, 8* 3, 8* 3 , 8* 3 (Total 4 bathces of data)\n",
    "#### All these 4bathces are trained in parallel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[70, 68, 61, 74,  8,  1, 69, 57],\n",
      "        [43, 57, 50, 63, 60,  1, 74, 64],\n",
      "        [ 1, 69, 57, 58, 63, 56,  1, 51],\n",
      "        [69, 64,  1, 54, 73, 54, 52, 70]])\n",
      "tensor([[68, 61, 74,  8,  1, 69, 57, 58],\n",
      "        [57, 50, 63, 60,  1, 74, 64, 70],\n",
      "        [69, 57, 58, 63, 56,  1, 51, 54],\n",
      "        [64,  1, 54, 73, 54, 52, 70, 69]])\n",
      "when context is [70] then 68\n",
      "when context is [70, 68] then 61\n",
      "when context is [70, 68, 61] then 74\n",
      "when context is [70, 68, 61, 74] then 8\n",
      "when context is [70, 68, 61, 74, 8] then 1\n",
      "when context is [70, 68, 61, 74, 8, 1] then 69\n",
      "when context is [70, 68, 61, 74, 8, 1, 69] then 57\n",
      "when context is [70, 68, 61, 74, 8, 1, 69, 57] then 58\n",
      "when context is [43] then 57\n",
      "when context is [43, 57] then 50\n",
      "when context is [43, 57, 50] then 63\n",
      "when context is [43, 57, 50, 63] then 60\n",
      "when context is [43, 57, 50, 63, 60] then 1\n",
      "when context is [43, 57, 50, 63, 60, 1] then 74\n",
      "when context is [43, 57, 50, 63, 60, 1, 74] then 64\n",
      "when context is [43, 57, 50, 63, 60, 1, 74, 64] then 70\n",
      "when context is [1] then 69\n",
      "when context is [1, 69] then 57\n",
      "when context is [1, 69, 57] then 58\n",
      "when context is [1, 69, 57, 58] then 63\n",
      "when context is [1, 69, 57, 58, 63] then 56\n",
      "when context is [1, 69, 57, 58, 63, 56] then 1\n",
      "when context is [1, 69, 57, 58, 63, 56, 1] then 51\n",
      "when context is [1, 69, 57, 58, 63, 56, 1, 51] then 54\n",
      "when context is [69] then 64\n",
      "when context is [69, 64] then 1\n",
      "when context is [69, 64, 1] then 54\n",
      "when context is [69, 64, 1, 54] then 73\n",
      "when context is [69, 64, 1, 54, 73] then 54\n",
      "when context is [69, 64, 1, 54, 73, 54] then 52\n",
      "when context is [69, 64, 1, 54, 73, 54, 52] then 70\n",
      "when context is [69, 64, 1, 54, 73, 54, 52, 70] then 69\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "batch_size = 4 ## No.of small independent sets for parallel training\n",
    "block_size = 8 ## Maximum context length for predictions \n",
    "\n",
    "def getbatch(split):\n",
    "    data = train if split == \"train\" else val\n",
    "\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "xb, yb = getbatch(\"train\")    \n",
    "    \n",
    "print(xb)\n",
    "print(yb)\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b,:t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when context is {context.tolist()} then {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3236, 19147, 25043,  1569])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(46954, (batch_size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42265"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a NN model using Bigramlanguagemodel(BLM)\n",
    "#### We pass inputs xb , yb to the BLM \n",
    "#### Get the embeddings for the inputs using the vocab size \n",
    "#### Apply embedding table on the inputs xb\n",
    "#### Transform the shapes of input and output according to CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([]) torch.Size([32, 77])\n",
      "tensor(4.8042, grad_fn=<NllLossBackward0>)\n",
      "['\\nDkx7kaC/W.6efJxoâ€™P6vm3 nye3 BQ:82DysaTpm:&d:ggrl6â€™ma?ma7jPUpi&7t-JV4a:2Ad4Hs\\n uHGYKFLaLhjfUpVi/p9E?-']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F \n",
    "torch.manual_seed(42)\n",
    "\n",
    "class BigramLanguagemodel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)## Gives the embeddings on the inputs\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.token_embedding_table(idx) ## (B batchsize, T block size , C Channels)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else :\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T, C)## Converting the shapes of the input to match loss function\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "                \n",
    "            # idx is (B batchsize, T block size) in the current context\n",
    "            logits, loss = self(idx)\n",
    "            #focus only on the last time step\n",
    "            logits = logits[:,-1,:] # Becomes B C\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim =1)#(B C)\n",
    "            #Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # B =1\n",
    "            # Append sample index to the running equence\n",
    "            idx = torch.cat((idx, idx_next), dim =1) # B* T+1\n",
    "        return idx\n",
    "\n",
    "\n",
    "m = BigramLanguagemodel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "\n",
    "print(loss.shape, logits.shape)\n",
    "print(loss)\n",
    "\n",
    "\n",
    "print(decode(m.generate(idx = torch.zeros((1,1), dtype = torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crearte Pytorch optimizer\n",
    "optimizer = torch.optim.Adam(m.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3883168697357178\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(20000):\n",
    "    # Sample of a batch of data\n",
    "    xb, yb = getbatch('train')\n",
    "    # evaluate the loss \n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"\\n\\n\\nAInen, permoitin Yomeve od bevear tind nond w cro to ct herklipre w ivewhesince Phiog.3 candinds bechingee ar arolse aco Cllitiod. t re wa quierores?\\n\\nAngre vern. to od th hasitilis Youbuglutorutstu pe we tile Picomickiout ompomerompalend ally. t'stedowill n TuTerng tiveds s, inuroberl atin we ti\\n\\n\\nIntrnipus, u cu. Andreme woges a d ie or. r anutewatizenar be Gote th ian ullern th d ldued thefur\"]\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1,1), dtype = torch.long)\n",
    "print(decode(m.generate(context, max_new_tokens=400)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Example \n",
    "torch.manual_seed(42)\n",
    "B,T,C = 4,8,2\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Initialize weights \n",
    "head_size = 16\n",
    "query = nn.Linear(C, head_size, bias = False)\n",
    "key = nn.Linear(C, head_size, bias = False)\n",
    "\n",
    "q = query(x)\n",
    "k = key(x)\n",
    "wei = q@k.transpose(-2, -1)* C**-0.5 # (B, T, 16) @ (B, 16, T) -> (B, T,T)\n",
    "\n",
    "#wei = torch.zeros(T,T)\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = wei.masked_fill(tril ==0, float('-inf'))\n",
    "wei = F.softmax(wei, dim =-1)\n",
    "\n",
    "value = nn.Linear(C, head_size, bias = False)\n",
    "val = value(x)\n",
    "out = wei@val\n",
    "\n",
    "out.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0179, 0.9821, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0563, 0.5513, 0.3924, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0144, 0.4238, 0.2111, 0.3507, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.7077, 0.0314, 0.0516, 0.0267, 0.1825, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0151, 0.3397, 0.1674, 0.2456, 0.0173, 0.2149, 0.0000, 0.0000],\n",
       "        [0.0614, 0.2745, 0.1769, 0.1867, 0.0369, 0.1607, 0.1029, 0.0000],\n",
       "        [0.3476, 0.0994, 0.1114, 0.0764, 0.1226, 0.0695, 0.0740, 0.0990]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
